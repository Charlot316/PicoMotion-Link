<!DOCTYPE html>
<html>
<head>
    <title>Pico 4 Ultra - VSSP v1.0 Ultra Low Latency</title>
    <meta charset="UTF-8">
    <style>
        body { margin: 0; background: #000; color: #fff; font-family: 'Inter', sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; overflow: hidden; }
        #overlay { position: fixed; inset: 0; background: rgba(0,0,0,0.8); z-index: 1000; display: flex; flex-direction: column; align-items: center; justify-content: center; backdrop-filter: blur(10px); }
        button { padding: 30px 60px; font-size: 24px; cursor: pointer; background: linear-gradient(135deg, #00f2ff, #0072ff); color: white; border: none; border-radius: 50px; box-shadow: 0 10px 30px rgba(0,242,255,0.3); transition: transform 0.2s; }
        button:active { transform: scale(0.95); }
        #status-panel { position: fixed; bottom: 20px; background: rgba(255,255,255,0.1); padding: 10px 20px; border-radius: 10px; font-family: monospace; font-size: 12px; display: flex; gap: 20px; color: #00f2ff; }
        .stat { display: flex; flex-direction: column; }
        .label { color: rgba(255,255,255,0.5); font-size: 9px; text-transform: uppercase; }
        #preview { border: 1px solid #333; max-width: 90%; max-height: 60vh; background: #050505; border-radius: 8px; }
        canvas { display: none; } /* XR rendering canvas */
    </style>
</head>
<body>
    <div id="overlay">
        <h1 style="font-weight: 200; letter-spacing: 5px;">PICO VSSP LINK</h1>
        <p style="color: rgba(255,255,255,0.5); margin-bottom: 30px;">点击下方按钮进入 VR 超低延迟同步模式</p>
        <button id="startBtn">开始同步 (VR Mode)</button>
    </div>

    <img id="preview" src="" alt="等待视频数据流..." />
    <canvas id="xrCanvas"></canvas>

    <div id="status-panel">
        <div class="stat"><span class="label">Network</span><span id="wsStatus">Disconnected</span></div>
        <div class="stat"><span class="label">VSSP Mode</span><span id="valMode">--</span></div>
        <div class="stat"><span class="label">Latency</span><span id="valLat">-- ms</span></div>
        <div class="stat"><span class="label">FPS</span><span id="valFps">0</span></div>
    </div>

    <script>
        const preview = document.getElementById('preview');
        const canvas = document.getElementById('xrCanvas');
        const gl = canvas.getContext('webgl', { xrCompatible: true });
        
        const poseUrl = `http://${window.location.hostname}:8765`;
        const wsUrl = `ws://${window.location.hostname}:8787`;

        let textureLeft = null;
        let textureRight = null;
        let isPresenting = false;
        let frameCount = 0;
        let lastFpsUpdate = performance.now();
        
        let lastBlobUrl = null;

        // 自动连接 WebSocket
        function connectVSSP() {
            const ws = new WebSocket(wsUrl);
            ws.binaryType = 'arraybuffer';
            
            ws.onopen = () => {
                document.getElementById('wsStatus').innerText = "VSSP CONNECTED";
                document.getElementById('wsStatus').style.color = "#44ff44";
            };

            ws.onmessage = (event) => {
                const buffer = event.data;
                const view = new DataView(buffer);
                
                // VSSP Header: size(4), mode(1), eye(1), codec(1)
                const dataSize = view.getUint32(0, true);
                const mode = view.getUint8(4);
                const eye = view.getUint8(5); // 0=Mono, 1=Left, 2=Right
                const codec = view.getUint8(6);
                const encodedData = new Uint8Array(buffer, 7);

                document.getElementById('valMode').innerText = (mode === 0 ? "MONO" : "STEREO");

                if (codec === 0) { // MJPEG
                    const blob = new Blob([encodedData], { type: 'image/jpeg' });
                    const url = URL.createObjectURL(blob);
                    
                    if (lastBlobUrl) URL.revokeObjectURL(lastBlobUrl);
                    lastBlobUrl = url;

                    if (!isPresenting) {
                        preview.src = url;
                    } else {
                        const img = new Image();
                        img.onload = () => {
                            if (mode === 0) { // Mono
                                textureLeft = updateVRTexture(img, textureLeft);
                                textureRight = textureLeft;
                            } else {
                                if (eye === 1) textureLeft = updateVRTexture(img, textureLeft);
                                if (eye === 2) textureRight = updateVRTexture(img, textureRight);
                            }
                            frameCount++;
                        };
                        img.src = url;
                    }
                }
            };

            ws.onclose = () => {
                document.getElementById('wsStatus').innerText = "RECONNECTING...";
                document.getElementById('wsStatus').style.color = "#ff4444";
                setTimeout(connectVSSP, 1000);
            };
        }

        connectVSSP();

        function updateVRTexture(image, existingTexture) {
            if (!gl || !image.complete) return existingTexture;
            let tex = existingTexture;
            if (!tex) {
                tex = gl.createTexture();
                gl.bindTexture(gl.TEXTURE_2D, tex);
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            }
            gl.bindTexture(gl.TEXTURE_2D, tex);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, image);
            return tex;
        }

        // --- WebGL / XR Logic ---
        const vsSource = `attribute vec2 position; attribute vec2 uv; varying vec2 vUv; void main() { vUv = uv; gl_Position = vec4(position, 0.0, 1.0); }`;
        const fsSource = `precision mediump float; varying vec2 vUv; uniform sampler2D uTexture; void main() { gl_FragColor = texture2D(uTexture, vUv); }`;
        function createShader(gl, type, source) { const s = gl.createShader(type); gl.shaderSource(s, source); gl.compileShader(s); return s; }
        const program = gl.createProgram();
        gl.attachShader(program, createShader(gl, gl.VERTEX_SHADER, vsSource));
        gl.attachShader(program, createShader(gl, gl.FRAGMENT_SHADER, fsSource));
        gl.linkProgram(program);
        const posBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, posBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1,-1, 1,-1, -1,1, 1,1]), gl.STATIC_DRAW);
        
        const uvBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, uvBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0,1, 1,1, 0,0, 1,0]), gl.STATIC_DRAW);

        async function startVR() {
            try {
                const session = await navigator.xr.requestSession('immersive-vr', { requiredFeatures: ['local-floor'] });
                document.getElementById('overlay').style.display = 'none';
                isPresenting = true;
                
                session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
                const refSpace = await session.requestReferenceSpace('local-floor');
                
                function onFrame(time, frame) {
                    session.requestAnimationFrame(onFrame);
                    const viewerPose = frame.getViewerPose(refSpace);
                    if (viewerPose) {
                        // 1. Post pose data
                        fetch(poseUrl, { method: 'POST', mode: 'no-cors', body: JSON.stringify({ 
                            type: 'head', 
                            position: viewerPose.transform.position, 
                            orientation: viewerPose.transform.orientation 
                        }) }).catch(() => {});

                        // 2. Render Video Stream 
                        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);
                        gl.clearColor(0,0,0,1);
                        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

                        gl.useProgram(program);
                        const posLoc = gl.getAttribLocation(program, 'position');
                        gl.enableVertexAttribArray(posLoc);
                        gl.bindBuffer(gl.ARRAY_BUFFER, posBuffer);
                        gl.vertexAttribPointer(posLoc, 2, gl.FLOAT, false, 0, 0);
                        
                        const uvLoc = gl.getAttribLocation(program, 'uv');
                        gl.enableVertexAttribArray(uvLoc);
                        gl.bindBuffer(gl.ARRAY_BUFFER, uvBuffer);
                        gl.vertexAttribPointer(uvLoc, 2, gl.FLOAT, false, 0, 0);
                        
                        for (const view of viewerPose.views) {
                            const viewport = session.renderState.baseLayer.getViewport(view);
                            gl.viewport(viewport.x, viewport.y, viewport.width, viewport.height);
                            
                            // 关键：根据眼部索引绑定不同的眼部纹理
                            let activeTex = (view.eye === 'left') ? textureLeft : textureRight;
                            if (activeTex) {
                                gl.bindTexture(gl.TEXTURE_2D, activeTex);
                                gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
                            }
                        }

                        // 3. Sync Controller Hands
                        for (const inputSource of session.inputSources) {
                            if (inputSource.gripSpace) {
                                const gripPose = frame.getPose(inputSource.gripSpace, refSpace);
                                if (gripPose) {
                                    const gamepad = inputSource.gamepad;
                                    fetch(poseUrl, { method: 'POST', mode: 'no-cors', body: JSON.stringify({ 
                                        type: 'controller', 
                                        handedness: inputSource.handedness, 
                                        position: gripPose.transform.position, 
                                        orientation: gripPose.transform.orientation,
                                        buttons: gamepad ? gamepad.buttons.map(b => ({ pressed: b.pressed, value: b.value })) : [],
                                        axes: gamepad ? [gamepad.axes[2], gamepad.axes[3]] : []
                                    }) }).catch(() => {});
                                }
                            }
                        }
                    }
                }
                session.requestAnimationFrame(onFrame);
            } catch (e) {
                alert("VR Start Failed: " + e.message);
            }
        }

        document.getElementById('startBtn').onclick = startVR;

        document.getElementById('startBtn').onclick = startVR;

        // FPS Pulse
        setInterval(() => {
            document.getElementById('valFps').innerText = frameCount;
            frameCount = 0;
        }, 1000);
    </script>
</body>
</html>